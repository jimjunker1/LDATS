% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/LDA_TS.R
\name{LDA_TS}
\alias{LDA_TS}
\title{Run a set of Linguistic Decomposition Analysis models coupled to
  Bayesian Time Series models}
\usage{
LDA_TS(data, topics = 2, reps = 1, formulas = ~1,
  nchangepoints = 0, timename = "time", weights = TRUE,
  control = list())
}
\arguments{
\item{data}{Any of the data structures allowable for LDATS analyses:
\code{matrix} or \code{data.frame} document term table, 
\code{list} of document term and covariate tables, a \code{list} of 
training and test sets of the two tables, or a \code{list} of multiple 
replicate splits of training and test sets of the two tables. \cr
See \code{\link{conform_data}}, which is used to ensure data structure
validity for the desired model.}

\item{topics}{\code{integer}-conformable \code{vector} of the number of 
topics to evaluate for each model. \cr
(See \code{\link{LDA}}.)}

\item{reps}{\code{integer}-conformable number of replicate starts to use 
for each value of \code{topics}. \cr
(See \code{\link{LDA}}.)}

\item{formulas}{Vector of \code{\link[stats]{formula}}(s) defining the 
regression between the change points. Any predictor variable included 
must also be a column in \code{data} and any (compositional) response 
variable must be a set of columns in \code{data}. \cr
Each element (formula) in the vector is evaluated for each number of 
change points and each LDA model. \cr
(See \code{\link{TS}}.)}

\item{nchangepoints}{\code{integer}-conformable vector corresponding to the 
number of change points to include in the models. 0 is valid (corresponds
to no change points, so a singular time series model) and the current 
implementation can reasonably include up to 6 change points. The 
number of change points is used to dictate the segmentation of the 
time series into chunks fit with separate models dictated by 
\code{formula}. \cr
Each element in the vector is the number of change points 
used to segment the data for each formula (entry in \code{formulas}) 
component of the TS model, for each selected LDA model. \cr
(See \code{\link{TS}}.)}

\item{timename}{\code{character} element indicating the time variable
used in the time series. Defaults to \code{"time"}. The variable must be
integer-conformable or a \code{Date}. If the variable named
is a \code{Date}, the input is converted to an integer, resulting in the
timestep being 1 day, which is often not desired behavior. \cr
(See \code{\link{TS}}.)}

\item{weights}{Optional class \code{numeric} vector of weights for each 
document. Defaults to \code{NULL}, translating to an equal weight for
each document. When using \code{\link{sequential_TS}} in a standard LDATS 
analysis, it is advisable to weight the documents by their total size,
as the result of, e.g., \code{\link[topicmodels]{LDA}} is a matrix of 
proportions, which does not account for size differences among documents.
For most models, a scaling of the weights (so that the average is 1) is
most appropriate, and this is accomplished using \code{document_weights}.
\cr
(See \code{\link{TS}}.)}

\item{control}{\code{list} of parameters to control the fitting of the
LDATS model. Values not input assume defaults set by 
\code{\link{LDA_TS_control}}.}
}
\value{
\code{LDA_TS} \code{list} with all fitted LDA and TS models and 
  selected models specifically as elements named
  \describe{
    \item{\code{LDA models}}{\code{list} of all and selected models as well
      as controls from \code{\link{LDA}}}
    \item{\code{TS models}}{\code{list} of all and selected models as well
      as controls from \code{\link{TS}}}
    \item{\code{control}}{\code{list} of overall model controls}
  }
}
\description{
The main interface function for analyzing compositional 
  time series using the LDATS application of Linguistic Decomposition 
  Analysis and Time Series modeling generally following Christensen 
  \emph{et al.} (2018).
}
\details{
For a (potentially subset) dataset consisting of counts of words 
  across multiple documents in a corpus, 
  \enumerate{
    \item Conduct multiple Linguistic Decomposition Analysis (LDA) models 
      (e.g., Latent Dirichlet Allocation using the Variational Expectation
      Maximization (VEM) algorithm; Blei \emph{et al.} 2003), 
    \item Select from the LDA model results to pick those used in the Time
      Series (TS) models,
    \item Conduct multiple compositional Bayesian TS models 
      (e.g., changepoint softmax regression; Ripley 1996, Venables 
      and Ripley 2002, Western and Kleykamp 2004, Bishop 2006, Ruggieri 
      2013) via a generalized linear modeling approach (McCullagh and 
      Nelder 1989) and using parallel tempering Markov Chain Monte Carlo
     (ptMCMC) methods (Earl and Deem 2005),
    \item Select from the TS model results to pick those used to summarize
      the whole model, and
    \item Package the results.
  }
}
\references{
Blei, D. M., A. Y. Ng, and M. I. Jordan. 2003. Latent Dirichlet
  Allocation. \emph{Journal of Machine Learning Research} 
  \strong{3}:993-1022.
  \href{http://jmlr.csail.mit.edu/papers/v3/blei03a.html}{link}.

  Bishop, C. M. 2006. \emph{Pattern Recognition and Machine Learning}. 
   Springer, New York, NY, USA.

  Christensen, E., D. J. Harris, and S. K. M. Ernest. 2018.
  Long-term community change through multiple rapid transitions in a 
  desert rodent community. \emph{Ecology} \strong{99}:1523-1529. 
  \href{https://doi.org/10.1002/ecy.2373}{link}.

  Earl, D. J. and M. W. Deem. 2005. Parallel tempering: theory, 
  applications, and new perspectives. \emph{Physical Chemistry Chemical 
  Physics} \strong{7}: 3910-3916.
  \href{https://doi.org/10.1039/B509983H}{link}.

  Grun B. and K. Hornik. 2011. topicmodels: An R Package for Fitting Topic
  Models. \emph{Journal of Statistical Software} \strong{40}:13.
  \href{https://www.jstatsoft.org/article/view/v040i13}{link}.

  McCullagh, P. and J. A. Nelder. 1989. \emph{Generalized Linear Models}.
  2nd Edition. Chapman and Hall, New York, NY, USA.

  Ripley, B. D. 1996. \emph{Pattern Recognition and Neural Networks}. 
  Cambridge University Press, Cambridge, UK.

  Ruggieri, E. 2013. A Bayesian approach to detecting change points in 
  climactic records. \emph{International Journal of Climatology}
  \strong{33}:520-528.
  \href{https://doi.org/10.1002/joc.3447}{link}.

  Venables, W. N. and B. D. Ripley. 2002. \emph{Modern and Applied
  Statistics with S}. Fourth Edition. Springer, New York, NY, USA.

  Western, B. and M. Kleykamp. 2004. A Bayesian change point model for 
  historical time series analysis. \emph{Political Analysis}
  \strong{12}:354-374.
  \href{https://doi.org/10.1093/pan/mph023}{link}.
}
